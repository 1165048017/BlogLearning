{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅仅替换眼鼻口\n",
    "参考博客：https://matthewearl.github.io/2015/07/28/switching-eds-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7c5500ca723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/haarcascade_frontalface_alt2.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateFacemarkLBF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/lbfmodel.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "cas = cv2.CascadeClassifier('./model/haarcascade_frontalface_alt2.xml')\n",
    "obj = cv2.face.createFacemarkLBF()\n",
    "obj.loadModel('./model/lbfmodel.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_facepoint(img):\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    print(img_gray.shape)\n",
    "    print(cas.detectMultiScale(img_gray,2,3,0,(30,30)))\n",
    "    faces = cas.detectMultiScale(img_gray,2,3,0,(30,30))\n",
    "    landmarks = obj.fit(img_gray,faces)\n",
    "    assert landmarks[0],'no face detected'\n",
    "    if(len(landmarks[1])>1):\n",
    "        print('multi face detected,use the first')\n",
    "    return faces[0],np.squeeze(landmarks[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kps(img,face_box,kps):\n",
    "    img_show = img.copy()\n",
    "    cv2.rectangle(img_show,(face_box[0],face_box[1]),(face_box[0]+face_box[2],face_box[1]+face_box[3]),(0,255,0),3)\n",
    "    for i in range(kps.shape[0]):\n",
    "        cv2.circle(img_show,(kps[i,0],kps[i,1]),2,(0,255,0),-1)\n",
    "    img_show = cv2.cvtColor(img_show,cv2.COLOR_BGR2RGB)\n",
    "    return img_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一种对齐方法\n",
    "把第二张图片对齐到第一张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_from_points(points1, points2):\n",
    "    points1 = points1.copy()\n",
    "    points2 = points2.copy()\n",
    "    points1 = points1.astype(np.float64)\n",
    "    points2 = points2.astype(np.float64)\n",
    "\n",
    "    c1 = np.mean(points1, axis=0)\n",
    "    c2 = np.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = np.std(points1)\n",
    "    s2 = np.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(np.dot(points1.T , points2))\n",
    "    R = (np.dot(U , Vt)).T \n",
    "    return np.vstack([np.hstack(((s2 / s1) * R,\n",
    "                                       np.array([c2.T - np.dot((s2 / s1) * R , c1.T)]).T )),\n",
    "                         np.array([0., 0., 1.])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_im(im,M,dshape):\n",
    "    output_im = np.zeros(dshape,dtype=im.dtype)\n",
    "    cv2.warpAffine(im,M[:2],(dshape[1],dshape[0]),dst=output_im,borderMode=cv2.BORDER_TRANSPARENT,flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_img1(img1,img2,landmarks1,landmarks2):\n",
    "    trans_mat = transformation_from_points(landmarks1, landmarks2)\n",
    "    img2_align = wrap_im(img2,trans_mat,img1.shape)\n",
    "    return img2_align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二种对齐方法\n",
    "把第二张图片对齐到第一张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_img2(img1,img2,landmarks1,landmarks2):\n",
    "    trans_mat,mask = cv2.findHomography(landmarks2, landmarks1, cv2.RANSAC,5.0)\n",
    "    img2_align = cv2.warpPerspective(img2.copy(),trans_mat,(img1.shape[1],img1.shape[0]))\n",
    "    return img2_align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 颜色校正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * np.linalg.norm(\n",
    "                              np.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              np.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "    # Avoid divide-by-zero errors.\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "\n",
    "    return (im2.astype(np.float64) * im1_blur.astype(np.float64) /im2_blur.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./images/hjh.jpg')\n",
    "img2 = cv2.imread('./images/zly.jpg')\n",
    "face_box1,face_kps1 = detect_facepoint(img1)\n",
    "face_kps1=face_kps1.astype(int)\n",
    "face_box2,face_kps2 = detect_facepoint(img2)\n",
    "face_kps2=face_kps2.astype(int)\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_kps(img1,face_box1,face_kps1))\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(draw_kps(img2,face_box2,face_kps2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_align = align_img1(img1,img2,face_kps1,face_kps2)\n",
    "plt.figure(figsize=[9,9])\n",
    "plt.subplot(131)\n",
    "plt.imshow(cv2.cvtColor(img1.copy(),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(cv2.cvtColor(img2_align.copy(),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "img2_align2 = align_img2(img1,img2,face_kps1,face_kps2)\n",
    "plt.subplot(133)\n",
    "plt.imshow(cv2.cvtColor(img2_align2.copy(),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 只贴眼鼻口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "OVERLAY_POINTS = [\n",
    "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS + MOUTH_POINTS,\n",
    "]\n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "\n",
    "def get_face_mask(im, landmarks):\n",
    "    im = np.zeros(im.shape[:2], dtype=np.float64)\n",
    "\n",
    "    for group in OVERLAY_POINTS:\n",
    "        draw_convex_hull(im,\n",
    "                         landmarks[group],\n",
    "                         color=1)\n",
    "\n",
    "    im = np.array([im, im, im]).transpose((1, 2, 0))\n",
    "\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_correct = correct_colours(img1,img2_align,face_kps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('img2_correct.png',img2_correct.copy().astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img2_correct.copy().astype('uint8'),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_face_mask(img2, face_kps2)\n",
    "warped_mask = align_img1(img1, mask,face_kps1,face_kps2)\n",
    "combined_mask = np.max([get_face_mask(img1, face_kps1), warped_mask],\n",
    "                          axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.multiply(img2_correct,combined_mask).astype('uint8')[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_im = img1 * (1.0 - combined_mask) + img2_correct * combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('output.png',output_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.imshow(output_im[...,::-1]/255)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
